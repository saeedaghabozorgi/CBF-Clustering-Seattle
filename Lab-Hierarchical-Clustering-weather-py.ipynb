{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src = https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png width = 200>\n",
    "<h1 align=center> Hierarchical Clustering in Python </h1>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Using this notebook:\n",
    "\n",
    "**Shift + Enter** to run a cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Weather Station Clustering \n",
    "\n",
    "## Hierarchical Clustering using python & scikit-learn¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### About the dataset\n",
    "\n",
    "Environment Canada\t\t  \n",
    "Monthly Values for June - 2015\t  \t\n",
    "\t\t\n",
    "Legend  \t\t\n",
    "Stn_Name::::\tStation Name  \n",
    "Lat\t    ::::\tLatitude (North + , degrees)  \n",
    "Long\t::::\tLongitude (West - , degrees)  \n",
    "Prov\t::::\tProvince  \n",
    "Tm\t    ::::\tMean Temperature (Â°C)  \n",
    "DwTm\t::::\tDays without Valid Mean Temperature  \n",
    "D\t    ::::\tMean Temperature difference from Normal (1981-2010) (Â°C)  \n",
    "Tx\t    ::::\tHighest Monthly Maximum Temperature (Â°C)  \n",
    "DwTx\t::::\tDays without Valid Maximum Temperature  \n",
    "Tn\t    ::::\tLowest Monthly Minimum Temperature (Â°C)  \n",
    "DwTn\t::::\tDays without Valid Minimum Temperature  \n",
    "S\t    ::::\tSnowfall (cm)  \n",
    "DwS\t    ::::\tDays without Valid Snowfall  \n",
    "S%N\t    ::::\tPercent of Normal (1981-2010) Snowfall  \n",
    "P\t    ::::\tTotal Precipitation (mm)  \n",
    "DwP\t    ::::\tDays without Valid Precipitation  \n",
    "P%N\t    ::::\tPercent of Normal (1981-2010) Precipitation  \n",
    "S_G  \t::::\tSnow on the ground at the end of the month (cm)  \n",
    "Pd\t    ::::\tNumber of days with Precipitation 1.0 mm or more  \n",
    "BS\t    ::::\tBright Sunshine (hours)  \n",
    "DwBS\t::::\tDays without Valid Bright Sunshine  \n",
    "BS%  \t::::\tPercent of Normal (1981-2010) Bright Sunshine  \n",
    "HDD \t::::\tDegree Days below 18 Â°C  \n",
    "CDD\t    ::::\tDegree Days above 18 Â°C  \n",
    "Stn_No\t::::\tClimate station identifier (first 3 digits indicate   drainage basin, last 4 characters are for sorting alphabetically).  \n",
    "NA\t    ::::\tNot Available  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 1-Download data into your Data Scientist Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!wget -O weather-stations20140101-20141231.csv https://ibm.box.com/shared/static/mv6g5p1wpmpvzoz6e5zgo47t44q8dvm0.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 2- Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filename='weather-stations20140101-20141231.csv'\n",
    "\n",
    "#Read csv\n",
    "pdf = pd.read_csv(filename)\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 3- Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pdf = pdf[pd.notnull(pdf[\"Tm\"]) & np.isfinite(pdf['Tm'])]\n",
    "pdf = pdf.reset_index(drop=True)\n",
    "pdf.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 4- Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (14,10)\n",
    "\n",
    "llon = -140\n",
    "ulon = -50\n",
    "llat = 40\n",
    "ulat = 65\n",
    "\n",
    "pdf = pdf[(pdf['Long'] > llon) & (pdf['Long'] < ulon) & (pdf['Lat'] > llat) &(pdf['Lat'] < ulat)]\n",
    "\n",
    "my_map = Basemap(projection='merc',\n",
    "            resolution = 'l', area_thresh = 1000.0,\n",
    "            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
    "            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n",
    "\n",
    "my_map.drawcoastlines()\n",
    "my_map.drawcountries()\n",
    "my_map.drawmapboundary()\n",
    "my_map.fillcontinents(color = 'white', alpha = 0.3)\n",
    "my_map.shadedrelief()\n",
    "\n",
    "# To collect data based on stations        \n",
    "\n",
    "xs,ys = my_map(np.asarray(pdf.Long), np.asarray(pdf.Lat))\n",
    "pdf['xm'] = xs.tolist()\n",
    "pdf['ym'] = ys.tolist()\n",
    "\n",
    "#Visualization1\n",
    "for index,row in pdf.iterrows():\n",
    "#   x,y = my_map(row.Long, row.Lat)\n",
    "   my_map.plot(row.xm, row.ym,markerfacecolor =([1,0,0]),  marker='o', markersize= 5, alpha = 0.75)\n",
    "#plt.text(x,y,stn)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 5- Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "my_randoms = random.sample(xrange(len(pdf)), 30)\n",
    "hpdf = pdf.ix[my_randoms,:]\n",
    "hpdf = hpdf.reset_index(drop=True)\n",
    "hpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 6- Data Clustering using average temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalization\n",
    "from sklearn.preprocessing import normalize\n",
    "import pylab\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib.pyplot \n",
    "%matplotlib inline\n",
    "Temper = np.asarray( hpdf['Tm'])\n",
    "\n",
    "nx = normalize(Temper.astype(float), axis=1)\n",
    "x = nx[0]\n",
    "D = scipy.zeros([x.size,x.size])\n",
    "for i in range(x.size):\n",
    "    for j in range(x.size):\n",
    "        D[i,j] = abs(x[i] - x[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 7- Plot the first dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "fig = pylab.figure(figsize=(8,8))\n",
    "ax1 = fig.add_axes([0.1,0.1,0.4,0.6])\n",
    "Y = sch.linkage(D, method='centroid')\n",
    "Z1 = sch.dendrogram(Y, orientation='right')\n",
    "ax1.set_xticks([])\n",
    "#ax1.set_yticks([])\n",
    "lb = zip(map(lambda x: round(x,2),Temper[Z1['leaves']]),hpdf['Stn_Name'][Z1['leaves']])\n",
    "ax1.set_yticklabels(lb)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 8-Clustering based on location and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Normalization\n",
    "from sklearn.preprocessing import normalize\n",
    "import pylab\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib.pyplot \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "x = normalize(np.asarray( hpdf['Tm']).astype(float), axis=1)[0]\n",
    "y = normalize(np.asarray( hpdf['Tn']).astype(float), axis=1)[0]\n",
    "z = normalize(np.asarray( hpdf['Tx']).astype(float), axis=1)[0]\n",
    "xm = normalize(np.asarray( hpdf['xm']).astype(float), axis=1)[0]\n",
    "ym = normalize(np.asarray( hpdf['ym']).astype(float), axis=1)[0]\n",
    "\n",
    "p=zip(x,y,z,xm,ym)\n",
    "\n",
    "\n",
    "D = scipy.zeros([x.size,x.size])\n",
    "for i in range(x.size):\n",
    "    for j in range(x.size):\n",
    "        D[i,j] = scipy.spatial.distance.euclidean(p[i], p[j])\n",
    "        #abs(x[i] - x[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 9-Visualization dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "fig = pylab.figure(figsize=(8,8))\n",
    "ax1 = fig.add_axes([0.1,0.1,0.4,0.6])\n",
    "Y = sch.linkage(D, method='centroid')\n",
    "Z1 = sch.dendrogram(Y, orientation='right')\n",
    "ax1.set_xticks([])\n",
    "#ax1.set_yticks([])\n",
    "lb=zip(map(lambda x: round(x,2),hpdf.Tx[Z1['leaves']]), \\\n",
    "       map(lambda x: round(x,2),hpdf.Tm[Z1['leaves']]), \\\n",
    "       map(lambda x: round(x,2),hpdf.Tn[Z1['leaves']]), \\\n",
    "       hpdf['Stn_Name'][Z1['leaves']],\\\n",
    "       map(lambda x: round(x,2),hpdf.Lat[Z1['leaves']]), \\\n",
    "       map(lambda x: round(x,2),hpdf.Long[Z1['leaves']]) \\\n",
    "      )\n",
    "ax1.set_yticklabels(lb)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 10- Clustering results (Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "labels = sch.fcluster(Y, 0.8*D.max(), 'distance')\n",
    "hpdf[\"Clus_hier\"]=labels-1\n",
    "clusterNum=labels.max()\n",
    "print (hpdf.Clus_hier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 11-Visualization of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (14,10)\n",
    "\n",
    "my_map = Basemap(projection='merc',\n",
    "            resolution = 'l', area_thresh = 1000.0,\n",
    "            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
    "            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n",
    "\n",
    "my_map.drawcoastlines()\n",
    "my_map.drawcountries()\n",
    "my_map.drawmapboundary()\n",
    "my_map.fillcontinents(color = 'white', alpha = 0.3)\n",
    "my_map.shadedrelief()\n",
    "\n",
    "# To create a color map\n",
    "colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))\n",
    "\n",
    "#Visualization1\n",
    "for index,row in hpdf.iterrows():\n",
    "    my_map.plot(row.xm, row.ym,markerfacecolor =colors[np.float(row.Clus_hier)],  marker='o', markersize= 5, alpha = 0.75)\n",
    "\n",
    "for i in range(clusterNum): \n",
    "    cluster=hpdf[[\"Stn_Name\",\"Tm\",\"xm\",\"ym\",\"Clus_hier\"]][hpdf.Clus_hier==i]\n",
    "    cenx=np.mean(cluster.xm) \n",
    "    ceny=np.mean(cluster.ym) \n",
    "    plt.text(cenx,ceny,str(i), fontsize=25, color='red',)\n",
    "    #print \"Cluster \"+str(i)+', Avg Temp: '+ str(np.mean(cluster.Tm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "\n",
    "IBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems – by your enterprise as a whole. A free trial is available through this course, available here: [SPSS Modeler for Mac users](https://cocl.us/ML0101EN_SPSSMod_mac) and [SPSS Modeler for Windows users](https://cocl.us/ML0101EN_SPSSMod_win)\n",
    "\n",
    "Also, you can use Data Science Experience to run these notebooks faster with bigger datasets. Data Science Experience is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, DSX enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of DSX users today with a free account at [Data Science Experience](https://cocl.us/ML0101EN_DSX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2016 [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks for completing this lesson!\n",
    "\n",
    "Notebook created by: <a href = \"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
