{
    "cells": [
        {
            "cell_type": "markdown", 
            "source": "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/wbqvbi6o6ip0vz55ua5gp17g4f1k7ve9.png\" width = 300, align = \"center\"></a>\n# <center>Density-Based Clustering</center>", 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "source": "### Some Notebook Commands Reminders:\n<ul>\n    <li>Run a cell: CTRL + ENTER</li>\n    <li>Create a cell above a cell: a</li>\n    <li>Create a cell below a cell: b</li>\n    <li>Change a cell to Markdown: m</li>\n    \n    <li>Change a cell to code: y</li>\n</ul>\n\n<b> If you are interested in more keyboard shortcuts, go to Help -> Keyboard Shortcuts </b>", 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "source": " In this section, the main focus will be manipulating the data and properties of DBSCAN and observing the resulting clustering.", 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "source": "Import the following libraries:\n<ul>\n    <li> <b>numpy as np</b> </li>\n    <li> <b>DBSCAN</b> from <b>sklearn.cluster</b> </li>\n    <li> <b>make_blobs</b> from <b>sklearn.datasets.samples_generator</b> </li>\n    <li> <b>StandardScaler</b> from <b>sklearn.preprocessing</b> </li>\n    <li> <b>matplotlib.pyplot as plt</b> </li>\n</ul> <br>\nRemember <b> %matplotlib inline </b> to display plots", 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "source": "import numpy as np \nfrom sklearn.cluster import DBSCAN \nfrom sklearn.datasets.samples_generator import make_blobs \nfrom sklearn.preprocessing import StandardScaler \nimport matplotlib.pyplot as plt \n%matplotlib inline", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "source": "The function below will generate the data points and requires these inputs:\n<ul>\n    <li> <b>centroidLocation</b>: Coordinates of the centroids that will generate the random data. </li>\n    <ul> <li> Example: input: [[4,3], [2,-1], [-1,4]] </li> </ul>\n    <li> <b>numSamples</b>: The number of data points we want generated, split over the number of centroids (# of centroids defined in centroidLocation) </li>\n    <ul> <li> Example: 1500 </li> </ul>\n    <li> <b>clusterDeviation</b>: The standard deviation between the clusters. The larger the number, the further the spacing. </li>\n    <ul> <li> Example: 0.5 </li> </ul>\n</ul>", 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "source": "def createDataPoints(centroidLocation, numSamples, clusterDeviation):\n    # Create random data and store in feature matrix X and response vector y.\n    X, y = make_blobs(n_samples=numSamples, centers=centroidLocation, \n                                cluster_std=clusterDeviation)\n    \n    # Standardize features by removing the mean and scaling to unit variance\n    X = StandardScaler().fit_transform(X)\n    return X, y", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "source": "Use <b>createDataPoints</b> with the <b>3 inputs</b> and store the output into variables <b>X</b> and <b>y</b>.", 
            "metadata": {}
        }, 
        {
            "cell_type": "code", 
            "source": "X, y = createDataPoints([[4,3], [2,-1], [-1,4]] , 1500, 0.5)", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "source": "epsilon = 0.3\nminimumSamples = 7\ndb = DBSCAN(eps=epsilon, min_samples=minimumSamples).fit(X)\nlabels = db.labels_\nlabels", 
            "execution_count": null, 
            "metadata": {}, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "source": "# Create an array of booleans using the labels from db.\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n# Replace all elements with 'True' in core_samples_mask that are\n# in the cluster, 'False' if the points are outliers.\ncore_samples_mask[db.core_sample_indices_] = True\ncore_samples_mask", 
            "execution_count": null, 
            "metadata": {}, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "source": "# Number of clusters in labels, ignoring noise if present.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_clusters_", 
            "execution_count": null, 
            "metadata": {}, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "source": "# Remove repetition in labels by turning it into a set.\nunique_labels = set(labels)\nunique_labels", 
            "execution_count": null, 
            "metadata": {}, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "source": "# Create colors for the clusters.\ncolors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\ncolors", 
            "execution_count": null, 
            "metadata": {}, 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "source": "# Plot the points with colors\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = 'k'\n\n    class_member_mask = (labels == k)\n\n    # Plot the datapoints that are clustered\n    xy = X[class_member_mask & core_samples_mask]\n    #plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,markeredgecolor='k', markersize=14)\n    plt.scatter(xy[:, 0], xy[:, 1],s=50, c=col, marker=u'o', alpha=0.5)\n\n    # Plot the outliers\n    xy = X[class_member_mask & ~core_samples_mask]\n    plt.scatter(xy[:, 0], xy[:, 1],s=50, c=col, marker=u'o', alpha=0.5)", 
            "execution_count": null, 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "source": "## Want to learn more?\n\nIBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems \u2013 by your enterprise as a whole. A free trial is available through this course, available here: [SPSS Modeler for Mac users](https://cocl.us/ML0101EN_SPSSMod_mac) and [SPSS Modeler for Windows users](https://cocl.us/ML0101EN_SPSSMod_win)\n\nAlso, you can use Data Science Experience to run these notebooks faster with bigger datasets. Data Science Experience is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, DSX enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of DSX users today with a free account at [Data Science Experience](https://cocl.us/ML0101EN_DSX)", 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "source": "---\n# Additional Resources\n<br>\nGeneral Clustering: http://scikit-learn.org/stable/modules/clustering.html \n<br><br>\nDensity-Based Clustering (DBSCAN): <br>\nhttps://www.youtube.com/watch?v=a69-jHtawEo <br>\nhttps://www.youtube.com/watch?v=5E097ZLE9Sg", 
            "metadata": {}
        }, 
        {
            "cell_type": "markdown", 
            "source": "<hr>\nCopyright &copy; 2016 [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).\u200b", 
            "metadata": {}
        }
    ], 
    "nbformat_minor": 1, 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "language": "python", 
            "display_name": "Python 2 with Spark 1.6", 
            "name": "python2"
        }, 
        "widgets": {
            "state": {}, 
            "version": "1.1.2"
        }, 
        "language_info": {
            "pygments_lexer": "ipython2", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "name": "python", 
            "file_extension": ".py", 
            "version": "2.7.11", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }
}